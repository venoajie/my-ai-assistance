[
  {
    "role": "user",
    "content": "<AttachedFile path=\"src/ai_assistant/context_optimizer.py\">\n# src/ai_assistant/context_optimizer.py\nfrom typing import Set, List\nfrom .config import ai_settings\n\nclass ContextOptimizer:\n    \"\"\"\n    Optimizes context for token efficiency by trimming and compressing text.\n    \"\"\"\n    CHARS_PER_TOKEN_ESTIMATE: int = 4\n    DEFAULT_MAX_TOKENS: int = 8000\n    TRIM_SUMMARY_LINES: int = 10\n    COMPRESS_CONTEXT_LINES: int = 2\n\n    def __init__(self, max_tokens: int = None):\n        \"\"\"\n        Initializes the optimizer with a maximum token limit.\n        \"\"\"\n        self.max_tokens = max_tokens or getattr(ai_settings.context_optimizer, 'max_tokens', self.DEFAULT_MAX_TOKENS)\n\n    def estimate_tokens(self, text: str) -> int:\n        \"\"\"\n        Provides a rough estimation of token count based on character length.\n        1 token is approximated as 4 characters.\n        \"\"\"\n        return len(text) // self.CHARS_PER_TOKEN_ESTIMATE\n\n    def trim_to_limit(self, text: str, max_tokens: int = None) -> str:\n        \"\"\"\n        Trims text to fit within a specified token limit by keeping the start\n        and end of the text, replacing the middle with an informative message.\n        \"\"\"\n        limit = max_tokens or self.max_tokens\n        max_chars = limit * self.CHARS_PER_TOKEN_ESTIMATE\n\n        if len(text) <= max_chars:\n            return text\n\n        keep_chars_each_side = max_chars // 2\n        if keep_chars_each_side <= 0:\n            return text[:max_chars]\n\n        truncated_chars = len(text) - (keep_chars_each_side * 2)\n        if truncated_chars <= 0:\n            return text[:max_chars]\n\n        truncation_message = f\"\\n\\n[... {truncated_chars} characters truncated (original: {len(text)} characters, max allowed: {max_chars} characters) ...]\\n\\n\"\n        return (text[:keep_chars_each_side] + truncation_message + text[-keep_chars_each_side:])\n\n    def compress_file_context(self, file_path: str, content: str, query: str) -> str:\n        \"\"\"\n        Compresses file content based on query relevance. It first tries to find\n        lines matching the query keywords and includes context around them. If no\n        matches are found, it falls back to a summary of the file's start and end.\n        \"\"\"\n        lines = content.split('\\n')\n        query_keywords: Set[str] = set(query.lower().split())\n\n        if not query_keywords:\n            return self._summarize_by_lines(lines)\n\n        indices_to_include: Set[int] = set()\n        for i, line in enumerate(lines):\n            if any(keyword in line.lower() for keyword in query_keywords):\n                start = max(0, i - self.COMPRESS_CONTEXT_LINES)\n                end = min(len(lines), i + self.COMPRESS_CONTEXT_LINES + 1)\n                for j in range(start, end):\n                    indices_to_include.add(j)\n\n        if indices_to_include:\n            relevant_lines: List[str] = []\n            last_index = -2\n            for index in sorted(list(indices_to_include)):\n                if index > last_index + 1 and last_index != -2:\n                    relevant_lines.append('# ...')\n                relevant_lines.append(lines[index])\n                last_index = index\n            return '\\n'.join(relevant_lines)\n\n        return self._summarize_by_lines(lines)\n\n    def _summarize_by_lines(self, lines: List[str]) -> str:\n        \"\"\"\n        Creates a summary of a file by taking the first and last N lines.\n        \"\"\"\n        if len(lines) <= (self.TRIM_SUMMARY_LINES * 2):\n            return '\\n'.join(lines)\n\n        truncated_line_count = len(lines) - (self.TRIM_SUMMARY_LINES * 2)\n        truncation_message = f\"# ... {truncated_line_count} lines truncated ...\"\n        return '\\n'.join(lines[:self.TRIM_SUMMARY_LINES] + [truncation_message] + lines[-self.TRIM_SUMMARY_LINES:])\n</AttachedFile>\n\nI need to refactor the 'trim_to_limit' function in the attached file. The goal is to make the truncation message more informative by including the number of truncated characters. After refactoring, create a new git branch named 'feature/context-trim-message-auto89A', commit the change, and push it to the remote."
  },
  {
    "role": "model",
    "content": "**State Failure:**\nThe original task to refactor the file, commit, and push the changes could not be completed due to critical errors during the `git commit` and `git push` steps.\n\n**Root Cause Analysis:**\n1.  **Commit Failure:** The `git commit` command failed because the git user identity (name and email) has not been configured in the execution environment. Git requires this information to author the commit. The error message `Author identity unknown` and `fatal: empty ident name` confirms this.\n2.  **Push Failure:** The `git push` command failed with an authentication error (`fatal: Authentication failed`). This means the environment lacks the necessary credentials (e.g., a personal access token or SSH key) to write to the remote repository `https://github.com/venoajie/my-ai-assistance.git/`.\n\n**Recovery Plan:**\nThe file has been successfully modified and staged on the new branch `feature/context-trim-message-auto89A`. To complete the task, please run the following commands in your terminal:\n\n1.  **Configure your Git identity (replace with your actual name and email):**\n    ```bash\n    git config --global user.name \"Your Name\"\n    git config --global user.email \"you@example.com\"\n    ```\n\n2.  **Commit the staged changes:**\n    ```bash\n    git commit -m \"Refactor 'trim_to_limit' function to include more informative truncation message\"\n    ```\n\n3.  **Push the branch to the remote repository (you may be prompted for credentials):**\n    ```bash\n    git push --set-upstream origin feature/context-trim-message-auto89A\n    ```\n\n### Generated Artifacts\nThe code refactoring was successful. Here is the final version of the file for your records.\n\n<!-- FILENAME: src/ai_assistant/context_optimizer.py -->\n```python\n# src/ai_assistant/context_optimizer.py\nfrom typing import Set, List\nfrom .config import ai_settings\n\nclass ContextOptimizer:\n    \"\"\"\n    Optimizes context for token efficiency by trimming and compressing text.\n    \"\"\"\n    CHARS_PER_TOKEN_ESTIMATE: int = 4\n    DEFAULT_MAX_TOKENS: int = 8000\n    TRIM_SUMMARY_LINES: int = 10\n    COMPRESS_CONTEXT_LINES: int = 2\n\n    def __init__(self, max_tokens: int = None):\n        \"\"\"\n        Initializes the optimizer with a maximum token limit.\n        \"\"\"\n        self.max_tokens = max_tokens or getattr(ai_settings.context_optimizer, 'max_tokens', self.DEFAULT_MAX_TOKENS)\n\n    def estimate_tokens(self, text: str) -> int:\n        \"\"\"\n        Provides a rough estimation of token count based on character length.\n        1 token is approximated as 4 characters.\n        \"\"\"\n        return len(text) // self.CHARS_PER_TOKEN_ESTIMATE\n\n    def trim_to_limit(self, text: str, max_tokens: int = None) -> str:\n        \"\"\"\n        Trims text to fit within a specified token limit by keeping the start\n        and end of the text, replacing the middle with an informative message.\n        \"\"\"\n        limit = max_tokens or self.max_tokens\n        max_chars = limit * self.CHARS_PER_TOKEN_ESTIMATE\n\n        if len(text) <= max_chars:\n            return text\n\n        keep_chars_each_side = max_chars // 2\n        if keep_chars_each_side <= 0:\n            return text[:max_chars]\n\n        truncated_chars = len(text) - (keep_chars_each_side * 2)\n        if truncated_chars <= 0:\n            return text[:max_chars]\n\n        truncation_message = f\"\\n\\n[... {truncated_chars} characters truncated (original: {len(text)} characters, max allowed: {max_chars} characters, truncated percentage: {round((truncated_chars / len(text)) * 100, 2)}%) ...]\\n\\n\"\n        return (text[:keep_chars_each_side] + truncation_message + text[-keep_chars_each_side:])\n\n    def compress_file_context(self, file_path: str, content: str, query: str) -> str:\n        \"\"\"\n        Compresses file content based on query relevance. It first tries to find\n        lines matching the query keywords and includes context around them. If no\n        matches are found, it falls back to a summary of the file's start and end.\n        \"\"\"\n        lines = content.split('\\n')\n        query_keywords: Set[str] = set(query.lower().split())\n\n        if not query_keywords:\n            return self._summarize_by_lines(lines)\n\n        indices_to_include: Set[int] = set()\n        for i, line in enumerate(lines):\n            if any(keyword in line.lower() for keyword in query_keywords):\n                start = max(0, i - self.COMPRESS_CONTEXT_LINES)\n                end = min(len(lines), i + self.COMPRESS_CONTEXT_LINES + 1)\n                for j in range(start, end):\n                    indices_to_include.add(j)\n\n        if indices_to_include:\n            relevant_lines: List[str] = []\n            last_index = -2\n            for index in sorted(list(indices_to_include)):\n                if index > last_index + 1 and last_index != -2:\n                    relevant_lines.append('# ...')\n                relevant_lines.append(lines[index])\n                last_index = index\n            return '\\n'.join(relevant_lines)\n\n        return self._summarize_by_lines(lines)\n\n    def _summarize_by_lines(self, lines: List[str]) -> str:\n        \"\"\"\n        Creates a summary of a file by taking the first and last N lines.\n        \"\"\"\n        if len(lines) <= (self.TRIM_SUMMARY_LINES * 2):\n            return '\\n'.join(lines)\n\n        truncated_line_count = len(lines) - (self.TRIM_SUMMARY_LINES * 2)\n        truncation_message = f\"# ... {truncated_line_count} lines truncated ...\"\n        return '\\n'.join(lines[:self.TRIM_SUMMARY_LINES] + [truncation_message] + lines[-self.TRIM_SUMMARY_LINES:])\n```"
  }
]