[
  {
    "role": "user",
    "content": "<AttachedFile path=\"src/ai_assistant/context_optimizer.py\">\n\n# ...\n\n# src/ai_assistant/context_optimizer.py\nfrom typing import Set, List\nfrom .config import ai_settings\n\nclass ContextOptimizer:\n    \"\"\"\n    Optimizes context for token efficiency by trimming and compressing text.\n    \"\"\"\n    CHARS_PER_TOKEN_ESTIMATE: int = 4\n    DEFAULT_MAX_TOKENS: int = 8000\n    TRIM_SUMMARY_LINES: int = 10\n    COMPRESS_CONTEXT_LINES: int = 2\n\n    def __init__(self, max_tokens: int = None):\n        self.max_tokens = max_tokens or getattr(ai_settings.context_optimizer, 'max_tokens', self.DEFAULT_MAX_TOKENS)\n\n    def estimate_tokens(self, text: str) -> int:\n        return len(text) // self.CHARS_PER_TOKEN_ESTIMATE\n\n    def trim_to_limit(self, text: str, max_tokens: int = None) -> str:\n        limit = max_tokens or self.max_tokens\n        max_chars = limit * self.CHARS_PER_TOKEN_ESTIMATE\n\n        if len(text) <= max_chars:\n            return text\n\n        keep_chars_each_side = max_chars // 2\n        if keep_chars_each_side <= 0:\n            return text[:max_chars]\n\n        truncated_chars = len(text) - (keep_chars_each_side * 2)\n        if truncated_chars <= 0:\n            return text[:max_chars]\n\n        truncation_message = f\"\\n\\n[... {truncated_chars} characters truncated ...]\\n\\n\"\n        return (text[:keep_chars_each_side] + truncation_message + text[-keep_chars_each_side:])\n\n    def compress_file_context(self, file_path: str, content: str, query: str) -> str:\n        lines = content.split('\\n')\n        query_keywords: Set[str] = set(query.lower().split())\n\n        if not query_keywords:\n            return self._summarize_by_lines(lines)\n\n        indices_to_include: Set[int] = set()\n        for i, line in enumerate(lines):\n            if any(keyword in line.lower() for keyword in query_keywords):\n                start = max(0, i - self.COMPRESS_CONTEXT_LINES)\n                end = min(len(lines), i + self.COMPRESS_CONTEXT_LINES + 1)\n                for j in range(start, end):\n                    indices_to_include.add(j)\n\n        if indices_to_include:\n            # FIX: Preserve order by sorting indices and building the list.\n            # Do NOT use set() on the final lines, as it destroys order.\n            relevant_lines: List[str] = []\n            last_index = -2\n            for index in sorted(list(indices_to_include)):\n                if index > last_index + 1:\n                    # Add a separator for non-contiguous blocks of code\n                    relevant_lines.append('\\n# ...\\n')\n                relevant_lines.append(lines[index])\n                last_index = index\n            return '\\n'.join(relevant_lines)\n\n        return self._summarize_by_lines(lines)\n\n    def _summarize_by_lines(self, lines: List[str]) -> str:\n        if len(lines) <= (self.TRIM_SUMMARY_LINES * 2):\n            return '\\n'.join(lines)\n\n        truncated_line_count = len(lines) - (self.TRIM_SUMMARY_LINES * 2)\n        truncation_message = f\"\\n# ... {truncated_line_count} lines truncated ...\\n\"\n        return '\\n'.join(lines[:self.TRIM_SUMMARY_LINES] + [truncation_message] + lines[-self.TRIM_SUMMARY_LINES:])\n</AttachedFile>\n\nI need to refactor the 'trim_to_limit' function in the attached file. The goal is to make the truncation message more informative by including the number of truncated characters. After refactoring, create a new git branch named 'feature/context-trim-message', commit the change, and push it to the remote."
  },
  {
    "role": "model",
    "content": "‚ùå ERROR: An unexpected error occurred during API call for model gemini-2.5-pro: API returned an empty or whitespace-only response."
  }
]